<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Yibo Liu</title>
    <meta name="description" content="Personal webpage">
    <link rel="icon" href="/logo.png">
    
    <link rel="preload" href="/assets/css/0.styles.111da671.css" as="style"><link rel="preload" href="/assets/js/app.2006503b.js" as="script"><link rel="preload" href="/assets/js/2.4d7c2de1.js" as="script"><link rel="preload" href="/assets/js/7.e790c766.js" as="script"><link rel="preload" href="/assets/js/4.421bff82.js" as="script"><link rel="preload" href="/assets/js/5.93671bdf.js" as="script"><link rel="prefetch" href="/assets/js/10.9741412a.js"><link rel="prefetch" href="/assets/js/11.73363121.js"><link rel="prefetch" href="/assets/js/12.6a109984.js"><link rel="prefetch" href="/assets/js/13.f514aca3.js"><link rel="prefetch" href="/assets/js/14.f06de240.js"><link rel="prefetch" href="/assets/js/15.c82574c4.js"><link rel="prefetch" href="/assets/js/16.53983558.js"><link rel="prefetch" href="/assets/js/17.8caa5565.js"><link rel="prefetch" href="/assets/js/18.8645afb5.js"><link rel="prefetch" href="/assets/js/3.d71d2c2d.js"><link rel="prefetch" href="/assets/js/6.d86c8b7f.js"><link rel="prefetch" href="/assets/js/8.c6c3058e.js"><link rel="prefetch" href="/assets/js/9.9ce8db49.js">
    <link rel="stylesheet" href="/assets/css/0.styles.111da671.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar home-page"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-exact-active router-link-active"><!----> <span class="site-name">Yibo Liu</span></a> <div class="links"><!----> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link router-link-exact-active router-link-active">Home</a></div><div class="nav-item"><a href="/projects/" class="nav-link">Projects</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link router-link-exact-active router-link-active">Home</a></div><div class="nav-item"><a href="/projects/" class="nav-link">Projects</a></div> <!----></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><div class="profile"><div class="image"><img src="/myprofile2.jpeg" alt></div> <div class="info"><div class="name">
      Yibo Liu
    </div> <div class="bio"><p>CS PhD Candidate @ UVic</p></div> <div class="socials"><div><a href="https://scholar.google.com/citations?user=FQExy98AAAAJ&amp;hl=en&amp;oi=ao" target="_blank"><img src="/icons/google-scholar.svg" alt="google-scholar" title="google-scholar"></a></div><div><a href="https://github.com/xDarkLemon" target="_blank"><img src="/icons/github.svg" alt="github" title="github"></a></div><div><a href="https://www.linkedin.com/in/yibo-liu-5a60a21b5/" target="_blank"><img src="/icons/linkedin.svg" alt="linkedin" title="linkedin"></a></div><div><a href="https://twitter.com/_liuyibo" target="_blank"><img src="/icons/twitter.svg" alt="twitter" title="twitter"></a></div><div><a href="/files/Yibo_Liu_CV_GM.pdf" target="_blank"><img src="/icons/cv.svg" alt="CV" title="CV"></a></div></div> <div class="contact"><div title="Contact me" class="email">liuyibo (at) uvic (dot) ca</div></div> <!----></div></div> <h2 id="about">About</h2> <p>I am Yibo Liu, a second year Ph.D. student in Computer Science at University of Victoria (<a href="https://www.uvic.ca/" target="_blank" rel="noopener noreferrer">UVIC<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>), working with <a href="http://web.uvic.ca/~teseo/" target="_blank" rel="noopener noreferrer">Prof. Dr. Teseo Schneider<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> . Prior to this, I obtained my M.S. in Computer Science from New York University (<a href="https://www.nyu.edu/" target="_blank" rel="noopener noreferrer">NYU<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>) and B.Eng. in Electronic Engineering from Beijing University of Posts and Telecommunications (<a href="https://www.bupt.edu.cn/" target="_blank" rel="noopener noreferrer">BUPT<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>). Previously, I have interned at Microsoft Research Asia (<a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/" target="_blank" rel="noopener noreferrer">MSRA<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>).</p> <p>My current research focuses on computer graphics, geometry modeling, and AI4Science, particularly on leveraging generative AI (e.g. LLMs) and learning-based paradigms to enhance physics-based simulations.</p> <h2 id="experience">Experience</h2> <ul><li><p><strong>Univerisity of Victoria</strong> | Sept 2023 - Present  <br>
PhD student in Computer Science <br>
Supervisor: <a href="http://web.uvic.ca/~teseo/" target="_blank" rel="noopener noreferrer">Prof. Dr. Teseo Schneider<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <br></p></li> <li><p><strong>Geometric Computing Lab, New York University</strong> | 2022 - 2023 <br>
Independent Study, supervised by <a href="http://web.uvic.ca/~teseo/" target="_blank" rel="noopener noreferrer">Prof. Dr. Teseo Schneider<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> and <a href="https://cims.nyu.edu/gcl/daniele.html" target="_blank" rel="noopener noreferrer">Prof. Dr. Daniele Panozzo<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <br>
Conducting research on GPU acceleration for contact simulations in <a href="http://github.com/polyfem/polyfem" target="_blank" rel="noopener noreferrer">PolyFEM<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> library.</p></li> <li><p><strong>Microsoft Research Asia</strong> | Aug 2020 - Feb 2021  <br>
R&amp;D Intern at <em>Data, Knowledge and Intelligence</em> group, full-time, onsite <br>
Conducted research on recommending charts from tables (Table2Charts) using reinforcement learning, delivering the technique to Bing Search and Excel Spreadsheet Intelligence, and developed a multilingual key-phrase extraction algorithm used in Forms Ideas and Teams polls.</p></li> <li><p><strong>CILVR Lab, New York University</strong> | Mar 2020 - May 2021 <br>
Independent Study, supervised by <a href="http://iacercalixto.github.io" target="_blank" rel="noopener noreferrer">Prof. Dr. Iacer Calixto<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> and <a href="http://claravania.github.io" target="_blank" rel="noopener noreferrer">Dr. Clara Vania<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><br>
Conducting research on learning robust mulilingual multimodal knowledge graph representations.</p></li> <li><p><strong>Center for Speech and Language Technologies, Tsinghua University</strong> | 2018 - 2019<br>
Research intern, supervised by <a href="http://wangd.cslt.org" target="_blank" rel="noopener noreferrer">Prof. Dr. Dong Wang<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <br>
Conducting research on poetry generation with rythm (YunLv) as soft constraint.</p></li></ul> <h2 id="publication">Publication</h2> <div class="md-card show-border"><div class="card-image"><img src="/projects/duck.png" alt></div> <div class="card-content"><p><strong>Neural Kinematic Bases for Fluids</strong></p> <p><strong>Yibo Liu</strong>, Zhixin Fang, Sune Darkner, Noam Aigerman, Kenny Erleben, Paul Kry, Teseo Schneider</p> <p>[<a href="https://arxiv.org/abs/2504.15657" target="_blank" rel="noopener noreferrer">Paper<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="TODO">Demo</a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/crowds.png" alt></div> <div class="card-content"><p><strong>Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions</strong></p> <p><em>In Submission</em></p> <p>[<a href="TODO">Paper</a>] [<a href="TODO">Demo</a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/01.png" alt></div> <div class="card-content"><p><strong>MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI</strong></p> <p>Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, <strong>Yibo Liu</strong>, Wenhao Huang, Huan Sun, Yu Su, Wenhu Chen</p> <p><strong>[CVPR 2024 Best Paper Nomination]</strong> <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp. 9556-9567, Jun. 2024</p> <p>[<a href="https://arxiv.org/abs/2311.16502" target="_blank" rel="noopener noreferrer">Paper<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://mmmu-benchmark.github.io" target="_blank" rel="noopener noreferrer">Web Page<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/02.png" alt></div> <div class="card-content"><p><strong>Endowing Language Models with Multimodal Knowledge Graph Representations</strong></p> <p>Ningyuan Huang, Yash R. Deshpande, <strong>Yibo Liu</strong>, Houda Alberts, Kyunghyun Cho, Clara Vania, Iacer Calixto</p> <p><em>arXiv</em> 2206.13163, Jun. 2022</p> <p>[<a href="https://arxiv.org/abs/2206.13163" target="_blank" rel="noopener noreferrer">Paper<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/03.png" alt></div> <div class="card-content"><p><strong>VisualSem: a high-quality knowledge graph for vision and language</strong></p> <p>Houda Alberts, Ningyuan Huang, Yash Deshpande, <strong>Yibo Liu</strong>, Kyunghyun Cho, Clara Vania, Iacer Calixto</p> <p><em>Proceedings of the 1st Workshop on Multilingual Representation Learning</em>, pp. 138-152, Nov. 2021. <em>(colocated with EMNLP 2021)</em></p> <p>[<a href="https://aclanthology.org/2021.mrl-1.13.pdfs" target="_blank" rel="noopener noreferrer">Paper<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/04.png" alt></div> <div class="card-content"><p><strong>Table2Charts: Recommending Charts by Learning Shared Table Representations</strong></p> <p>Mengyu Zhou, Qingtao Li, Xinyi He, Yuejiang Li , <strong>Yibo Liu</strong>, Wei Ji, Shi Han, Yining Chen, Daxin Jiang, Dongmei Zhang.</p> <p><em>Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, pp. 2389-2399, Aug. 2021</p> <p>[<a href="https://dl.acm.org/doi/pdf/10.1145/3447548.3467279" target="_blank" rel="noopener noreferrer">Paper<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://github.com/microsoft/Table2Charts" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <h2 id="open-source-contribution">Open-Source Contribution</h2> <div class="md-card show-border"><div class="card-image"><img src="/projects/ntm.png" alt></div> <div class="card-content"><p><strong>Neural Topic Model Library</strong></p> <ul><li>The first Python library containing all cutting-edge neural topic models, collaborated with <a href="https://scholar.google.com/citations?user=FDeI9yUAAAAJ&amp;hl=zh-CN" target="_blank" rel="noopener noreferrer">Leilan Zhang<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>.</li> <li>Refactored the codebase framework and rewrote the interfaces to provide APIs compatible with the Gensim LDA library.</li></ul> <p>[<a href="https://github.com/zll17/Neural_Topic_Models/tree/dev_b" target="_blank" rel="noopener noreferrer">GitHub | 431 star ⭐️ | 80 fork<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/polyfem.png" alt></div> <div class="card-content"><p><strong>PolyFEM</strong></p> <ul><li>Developed GPU acceleration for contact simulations.</li> <li>Profiled contact solvers in the PolyFEM library, identified performance bottlenecks.</li></ul> <p>[<a href="TODO">GitHub | 562 star ⭐️ | 88 fork</a>]</p></div></div> <h2 id="projects">Projects</h2> <p><a href="/projects/">→ Full list</a></p> <div class="md-card show-border"><div class="card-image"><img src="/projects/gpu.png" alt></div> <div class="card-content"><p><strong>Lock-free Linked List Library for GPUs</strong></p> <ul><li>This project develops a CUDA-based singly linked list library, with all operations running on GPUs to fully exploit their parallelism.</li> <li>It introduces the <strong>first</strong> lock-free linked list algorithm on CUDA, adapted from prior implementations on multi-core CPUs.</li></ul> <p>[<a href="https://github.com/xDarkLemon/concurrent_linked_list_cuda" target="_blank" rel="noopener noreferrer">GitHub<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="/files/gpu_final_report.pdf">Report</a>]</p></div></div> <h2 id="talks">Talks</h2> <p><strong>Oct 2021</strong> I presented our paper <em><a href="/files/MRL_slides.pdf">&quot;VisualSem: a high-quality knowledge graph for vision and language&quot;</a></em> at <a href="https://www.aclweb.org/portal/content/1st-workshop-multilingual-representation-learning-mrl-emnlp" target="_blank" rel="noopener noreferrer">EMNLP Workshop on Multilingual Representation Learning 2021<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>.</p> <h2 id="peer-review-service">Peer Review Service</h2> <p><strong>AAAI Conference on Artificial Intelligence (AAAI)</strong> Reviewer, 2025</p> <p><strong>International Conference on Learning Representations (ICLR)</strong> Reviewer, 2025</p> <p><strong>Transactions on Visualization and Computer Graphics (TVCG)</strong> Reviewer, 2024</p> <h2 id="volunteer">Volunteer</h2> <p><strong>SIGGRAPH Asia 2024</strong> Student Volunteer | Tokyo, Japan | Dec 2024</p> <h2 id="teaching-assistantship">Teaching Assistantship</h2> <p><strong>Introduction to Computer Graphics</strong> | University of Victoria | 2025 summer</p> <p><strong>Data Mining</strong> | University of Victoria | 2025 spring, 2024 winter, 2023 fall</p> <p><strong>Introduction to C++</strong> | University of Victoria | 2024 fall</p> <p><strong>Software Architecture</strong> | University of Victoria | 2024 fall</p> <h2 id="blender-art-gallery">Blender Art Gallery</h2></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">8/17/2025, 9:56:34 PM</span></div></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.2006503b.js" defer></script><script src="/assets/js/2.4d7c2de1.js" defer></script><script src="/assets/js/7.e790c766.js" defer></script><script src="/assets/js/4.421bff82.js" defer></script><script src="/assets/js/5.93671bdf.js" defer></script>
  </body>
</html>
